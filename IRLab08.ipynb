{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting num2words\n",
      "  Downloading num2words-0.5.10-py3-none-any.whl (101 kB)\n",
      "Collecting docopt>=0.6.2\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13709 sha256=14b1523bcf4d2f018422255437f0634d2807d033519694bc45ae9d315c224dfd\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\56\\ea\\58\\ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
      "Successfully built docopt\n",
      "Installing collected packages: docopt, num2words\n",
      "Successfully installed docopt-0.6.2 num2words-0.5.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "import os \n",
    "import string\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "from num2words import num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\mini_newsgroups\\\\comp.graphics/used/\\\\37916'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = \"used\"\n",
    "os.chdir(\"C:/mini_newsgroups/comp.graphics\")\n",
    "paths = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(str(os.getcwd())+'/'+title+'/'):\n",
    "    for i in filenames:\n",
    "        paths.append(str(dirpath)+str(\"\\\\\")+i) \n",
    "\n",
    "paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: cantaloupe.srv.cs.cmu.edu!crabapple.srv.cs.cmu.edu!fs7.ece.cmu.edu!europa.eng.gtefsd.com!gatech!asuvax!cs.utexas.edu!zaphod.mps.ohio-state.edu!saimiri.primate.wisc.edu!usenet.coe.montana.edu!news.u.washington.edu!uw-beaver!cs.ubc.ca!unixg.ubc.ca!kakwa.ucs.ualberta.ca!ersys!joth\n",
      "From: joth@ersys.edmonton.ab.ca (Joe Tham)\n",
      "Newsgroups: comp.graphics\n",
      "Subject: Where can I find SIPP?\n",
      "Message-ID: <yFXJ2B2w165w@ersys.edmonton.ab.ca>\n",
      "Date: Mon, 05 Apr 93 14:58:21 MDT\n",
      "Organization: Edmonton Remote Systems #2, Edmonton, AB, Canada\n",
      "Lines: 11\n",
      "\n",
      "        I recently got a file describing a library of rendering routines \n",
      "called SIPP (SImple Polygon Processor).  Could anyone tell me where I can \n",
      "FTP the source code and which is the newest version around?\n",
      "        Also, I've never used Renderman so I was wondering if Renderman \n",
      "is like SIPP?  ie. a library of rendering routines which one uses to make \n",
      "a program that creates the image...\n",
      "\n",
      "                                        Thanks,  Joe Tham\n",
      "\n",
      "--\n",
      "Joe Tham              joth@ersys.edmonton.ab.ca \n",
      "\n"
     ]
    }
   ],
   "source": [
    "myfile = open(paths[0])\n",
    "txt = myfile.read()\n",
    "print(txt)\n",
    "myfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(data):\n",
    "    stop_words = stopwords.words('english')\n",
    "    words = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "            new_text = new_text + \" \" + w\n",
    "    return np.char.strip(new_text) \n",
    "\n",
    "\n",
    "def remove_punctuation(data):\n",
    "    symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\n",
    "    for i in range(len(symbols)):\n",
    "        data = np.char.replace(data, symbols[i], ' ')\n",
    "        data = np.char.replace(data, \" \", \" \")\n",
    "    data = np.char.replace(data, ',', '')\n",
    "    return data \n",
    "\n",
    "def convert_lower_case(data):\n",
    "    return np.char.lower(data)\n",
    "\n",
    "def stemming(data):\n",
    "    stemmer= PorterStemmer()\n",
    "\n",
    "    tokens = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in tokens:\n",
    "        new_text = new_text + \" \" + stemmer.stem(w)\n",
    "    return np.char.strip(new_text) \n",
    "\n",
    "def convert_numbers(data):\n",
    "    data = np.char.replace(data, \"0\", \" zero \")\n",
    "    data = np.char.replace(data, \"1\", \" one \")\n",
    "    data = np.char.replace(data, \"2\", \" two \")\n",
    "    data = np.char.replace(data, \"3\", \" three \")\n",
    "    data = np.char.replace(data, \"4\", \" four \")\n",
    "    data = np.char.replace(data, \"5\", \" five \")\n",
    "    data = np.char.replace(data, \"6\", \" six \")\n",
    "    data = np.char.replace(data, \"7\", \" seven \")\n",
    "    data = np.char.replace(data, \"8\", \" eight \")\n",
    "    data = np.char.replace(data, \"9\", \" nine \")\n",
    "    return data \n",
    "\n",
    "def remove_header(data):\n",
    "    try:\n",
    "        ind = data.index('\\n\\n')\n",
    "        data = data[ind:]\n",
    "    except:\n",
    "        print(\"No Header\")\n",
    "    return data \n",
    "\n",
    "def remove_apostrophe(data):\n",
    "    return np.char.replace(data, \"'\", \"\") \n",
    "\n",
    "def remove_single_characters(data):\n",
    "    words = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in words:\n",
    "        if len(w) > 1:\n",
    "            new_text = new_text + \" \" + w\n",
    "    return np.char.strip(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    data = remove_header(data) \n",
    "    data = convert_lower_case(data)\n",
    "    data = convert_numbers(data)\n",
    "    data = remove_punctuation(data)\n",
    "    data = remove_stop_words(data)\n",
    "    data = remove_apostrophe(data)\n",
    "    data = remove_single_characters(data)\n",
    "    data = stemming(data) \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['recent', 'got', 'file', 'describ', 'librari', 'render', 'routin', 'call', 'sipp', 'simpl', 'polygon', 'processor', 'could', 'anyon', 'tell', 'ftp', 'sourc', 'code', 'newest', 'version', 'around', 'also', 've', 'never', 'use', 'renderman', 'wonder', 'renderman', 'like', 'sipp', 'ie', 'librari', 'render', 'routin', 'one', 'use', 'make', 'program', 'creat', 'imag', 'thank', 'joe', 'tham', 'joe', 'tham', 'joth', 'ersi', 'edmonton', 'ab', 'ca']]\n",
      "[['recent', 'got', 'file', 'describ', 'librari', 'render', 'routin', 'call', 'sipp', 'simpl', 'polygon', 'processor', 'could', 'anyon', 'tell', 'ftp', 'sourc', 'code', 'newest', 'version', 'around', 'also', 've', 'never', 'use', 'renderman', 'wonder', 'renderman', 'like', 'sipp', 'ie', 'librari', 'render', 'routin', 'one', 'use', 'make', 'program', 'creat', 'imag', 'thank', 'joe', 'tham', 'joe', 'tham', 'joth', 'ersi', 'edmonton', 'ab', 'ca'], ['hello', 'everybodi', 'use', 'pixar', 'renderman', 'three', 'scene', 'descript', 'languag', 'creat', 'three', 'world', 'pleas', 'help', 'use', 'renderman', 'librari', 'next', 'document', 'nextstep', 'version', 'renderman', 'avail', 'creat', 'complic', 'scene', 'render', 'use', 'surfac', 'shader', 'bring', 'life', 'appli', 'shadow', 'reflect', 'far', 'understand', 'defin', 'environment', 'shadow', 'map', 'produc', 'reflect', 'shadow', 'know', 'use', 'advis', 'simpl', 'rib', 'exampl', 'appreci', 'thank', 'advanc', 'alex', 'kolesov', 'moscow', 'russia', 'talu', 'imag', 'commun', 'corpor', 'mail', 'alex', 'talu', 'msk', 'su', 'next', 'mail', 'accept']]\n",
      "[['recent', 'got', 'file', 'describ', 'librari', 'render', 'routin', 'call', 'sipp', 'simpl', 'polygon', 'processor', 'could', 'anyon', 'tell', 'ftp', 'sourc', 'code', 'newest', 'version', 'around', 'also', 've', 'never', 'use', 'renderman', 'wonder', 'renderman', 'like', 'sipp', 'ie', 'librari', 'render', 'routin', 'one', 'use', 'make', 'program', 'creat', 'imag', 'thank', 'joe', 'tham', 'joe', 'tham', 'joth', 'ersi', 'edmonton', 'ab', 'ca'], ['hello', 'everybodi', 'use', 'pixar', 'renderman', 'three', 'scene', 'descript', 'languag', 'creat', 'three', 'world', 'pleas', 'help', 'use', 'renderman', 'librari', 'next', 'document', 'nextstep', 'version', 'renderman', 'avail', 'creat', 'complic', 'scene', 'render', 'use', 'surfac', 'shader', 'bring', 'life', 'appli', 'shadow', 'reflect', 'far', 'understand', 'defin', 'environment', 'shadow', 'map', 'produc', 'reflect', 'shadow', 'know', 'use', 'advis', 'simpl', 'rib', 'exampl', 'appreci', 'thank', 'advanc', 'alex', 'kolesov', 'moscow', 'russia', 'talu', 'imag', 'commun', 'corpor', 'mail', 'alex', 'talu', 'msk', 'su', 'next', 'mail', 'accept'], ['anybodi', 'know', 'good', 'two', 'graphic', 'packag', 'avail', 'ibm', 'rs', 'six', 'zero', 'zero', 'zero', 'aix', 'look', 'someth', 'like', 'dec', 'gk', 'hewlett', 'packard', 'starbas', 'reason', 'good', 'support', 'differ', 'output', 'devic', 'like', 'plotter', 'termin', 'etc', 'tri', 'also', 'xgk', 'one', 'one', 'distribut', 'ibm', 'implement', 'phig', 'work', 'requir', 'output', 'devic', 'window', 'salesman', 'ibm', 'familiar', 'graphic', 'expect', 'good', 'solut', 'ari', 'ari', 'suutari', 'ari', 'carel', 'fi', 'carelcomp', 'oy', 'lappeenranta', 'finland']]\n",
      "[['recent', 'got', 'file', 'describ', 'librari', 'render', 'routin', 'call', 'sipp', 'simpl', 'polygon', 'processor', 'could', 'anyon', 'tell', 'ftp', 'sourc', 'code', 'newest', 'version', 'around', 'also', 've', 'never', 'use', 'renderman', 'wonder', 'renderman', 'like', 'sipp', 'ie', 'librari', 'render', 'routin', 'one', 'use', 'make', 'program', 'creat', 'imag', 'thank', 'joe', 'tham', 'joe', 'tham', 'joth', 'ersi', 'edmonton', 'ab', 'ca'], ['hello', 'everybodi', 'use', 'pixar', 'renderman', 'three', 'scene', 'descript', 'languag', 'creat', 'three', 'world', 'pleas', 'help', 'use', 'renderman', 'librari', 'next', 'document', 'nextstep', 'version', 'renderman', 'avail', 'creat', 'complic', 'scene', 'render', 'use', 'surfac', 'shader', 'bring', 'life', 'appli', 'shadow', 'reflect', 'far', 'understand', 'defin', 'environment', 'shadow', 'map', 'produc', 'reflect', 'shadow', 'know', 'use', 'advis', 'simpl', 'rib', 'exampl', 'appreci', 'thank', 'advanc', 'alex', 'kolesov', 'moscow', 'russia', 'talu', 'imag', 'commun', 'corpor', 'mail', 'alex', 'talu', 'msk', 'su', 'next', 'mail', 'accept'], ['anybodi', 'know', 'good', 'two', 'graphic', 'packag', 'avail', 'ibm', 'rs', 'six', 'zero', 'zero', 'zero', 'aix', 'look', 'someth', 'like', 'dec', 'gk', 'hewlett', 'packard', 'starbas', 'reason', 'good', 'support', 'differ', 'output', 'devic', 'like', 'plotter', 'termin', 'etc', 'tri', 'also', 'xgk', 'one', 'one', 'distribut', 'ibm', 'implement', 'phig', 'work', 'requir', 'output', 'devic', 'window', 'salesman', 'ibm', 'familiar', 'graphic', 'expect', 'good', 'solut', 'ari', 'ari', 'suutari', 'ari', 'carel', 'fi', 'carelcomp', 'oy', 'lappeenranta', 'finland'], ['requir', 'bgi', 'driver', 'super', 'vga', 'display', 'super', 'xvga', 'display', 'anyon', 'know', 'could', 'obtain', 'relev', 'driver', 'ftp', 'site', 'regard', 'simon', 'crow']]\n"
     ]
    }
   ],
   "source": [
    "processed_text = []\n",
    "for i in range(len(filenames)):\n",
    "    file = open(dirpath+'/'+ filenames[i], 'r', encoding='cp1250', errors='ignore')\n",
    "    text = file.read().strip()\n",
    "    file.close()\n",
    "    \n",
    "    processed_text.append(word_tokenize(str(preprocess(text))))\n",
    "    print(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = {}\n",
    "N = len(processed_text)\n",
    "for i in range(N):\n",
    "    tokens = processed_text[i]\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            DF[w].add(i)\n",
    "        except:\n",
    "            DF[w] = {i}\n",
    "for i in DF:\n",
    "    DF[i] = len(DF[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recent': 1,\n",
       " 'got': 1,\n",
       " 'file': 1,\n",
       " 'describ': 1,\n",
       " 'librari': 2,\n",
       " 'render': 2,\n",
       " 'routin': 1,\n",
       " 'call': 1,\n",
       " 'sipp': 1,\n",
       " 'simpl': 2,\n",
       " 'polygon': 1,\n",
       " 'processor': 1,\n",
       " 'could': 2,\n",
       " 'anyon': 2,\n",
       " 'tell': 1,\n",
       " 'ftp': 2,\n",
       " 'sourc': 1,\n",
       " 'code': 1,\n",
       " 'newest': 1,\n",
       " 'version': 2,\n",
       " 'around': 1,\n",
       " 'also': 2,\n",
       " 've': 1,\n",
       " 'never': 1,\n",
       " 'use': 2,\n",
       " 'renderman': 2,\n",
       " 'wonder': 1,\n",
       " 'like': 2,\n",
       " 'ie': 1,\n",
       " 'one': 2,\n",
       " 'make': 1,\n",
       " 'program': 1,\n",
       " 'creat': 2,\n",
       " 'imag': 2,\n",
       " 'thank': 2,\n",
       " 'joe': 1,\n",
       " 'tham': 1,\n",
       " 'joth': 1,\n",
       " 'ersi': 1,\n",
       " 'edmonton': 1,\n",
       " 'ab': 1,\n",
       " 'ca': 1,\n",
       " 'hello': 1,\n",
       " 'everybodi': 1,\n",
       " 'pixar': 1,\n",
       " 'three': 1,\n",
       " 'scene': 1,\n",
       " 'descript': 1,\n",
       " 'languag': 1,\n",
       " 'world': 1,\n",
       " 'pleas': 1,\n",
       " 'help': 1,\n",
       " 'next': 1,\n",
       " 'document': 1,\n",
       " 'nextstep': 1,\n",
       " 'avail': 2,\n",
       " 'complic': 1,\n",
       " 'surfac': 1,\n",
       " 'shader': 1,\n",
       " 'bring': 1,\n",
       " 'life': 1,\n",
       " 'appli': 1,\n",
       " 'shadow': 1,\n",
       " 'reflect': 1,\n",
       " 'far': 1,\n",
       " 'understand': 1,\n",
       " 'defin': 1,\n",
       " 'environment': 1,\n",
       " 'map': 1,\n",
       " 'produc': 1,\n",
       " 'know': 3,\n",
       " 'advis': 1,\n",
       " 'rib': 1,\n",
       " 'exampl': 1,\n",
       " 'appreci': 1,\n",
       " 'advanc': 1,\n",
       " 'alex': 1,\n",
       " 'kolesov': 1,\n",
       " 'moscow': 1,\n",
       " 'russia': 1,\n",
       " 'talu': 1,\n",
       " 'commun': 1,\n",
       " 'corpor': 1,\n",
       " 'mail': 1,\n",
       " 'msk': 1,\n",
       " 'su': 1,\n",
       " 'accept': 1,\n",
       " 'anybodi': 1,\n",
       " 'good': 1,\n",
       " 'two': 1,\n",
       " 'graphic': 1,\n",
       " 'packag': 1,\n",
       " 'ibm': 1,\n",
       " 'rs': 1,\n",
       " 'six': 1,\n",
       " 'zero': 1,\n",
       " 'aix': 1,\n",
       " 'look': 1,\n",
       " 'someth': 1,\n",
       " 'dec': 1,\n",
       " 'gk': 1,\n",
       " 'hewlett': 1,\n",
       " 'packard': 1,\n",
       " 'starbas': 1,\n",
       " 'reason': 1,\n",
       " 'support': 1,\n",
       " 'differ': 1,\n",
       " 'output': 1,\n",
       " 'devic': 1,\n",
       " 'plotter': 1,\n",
       " 'termin': 1,\n",
       " 'etc': 1,\n",
       " 'tri': 1,\n",
       " 'xgk': 1,\n",
       " 'distribut': 1,\n",
       " 'implement': 1,\n",
       " 'phig': 1,\n",
       " 'work': 1,\n",
       " 'requir': 2,\n",
       " 'window': 1,\n",
       " 'salesman': 1,\n",
       " 'familiar': 1,\n",
       " 'expect': 1,\n",
       " 'solut': 1,\n",
       " 'ari': 1,\n",
       " 'suutari': 1,\n",
       " 'carel': 1,\n",
       " 'fi': 1,\n",
       " 'carelcomp': 1,\n",
       " 'oy': 1,\n",
       " 'lappeenranta': 1,\n",
       " 'finland': 1,\n",
       " 'bgi': 1,\n",
       " 'driver': 1,\n",
       " 'super': 1,\n",
       " 'vga': 1,\n",
       " 'display': 1,\n",
       " 'xvga': 1,\n",
       " 'obtain': 1,\n",
       " 'relev': 1,\n",
       " 'site': 1,\n",
       " 'regard': 1,\n",
       " 'simon': 1,\n",
       " 'crow': 1}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n"
     ]
    }
   ],
   "source": [
    "total_voca=len(DF)\n",
    "print(total_voca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_freq(word):\n",
    "    c = 0\n",
    "    try:\n",
    "        c = DF[word]\n",
    "    except:\n",
    "        pass\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the word is :  simpl the frequncey  0\n"
     ]
    }
   ],
   "source": [
    "Word = \"simpl\"\n",
    "print(\"the word is : \",Word,\"the frequncey \",doc_freq(Word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
