{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dogs            -> dog\n",
      "programming     -> program\n",
      "programs        -> program\n",
      "programmed      -> program\n",
      "cakes           -> cake\n",
      "indices         -> indic\n",
      "matrices        -> matric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('punkt')\n",
    "porter = PorterStemmer()\n",
    "l_words = ['dogs', 'programming', 'programs', 'programmed', 'cakes', 'indices', 'matrices']\n",
    "for word in l_words:\n",
    "    print(f'{word} \\t -> {porter.stem(word)}'.expandtabs(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A               -> A\n",
      "stemmer         -> stemmer\n",
      "for             -> for\n",
      "English         -> english\n",
      "operating       -> oper\n",
      "on              -> on\n",
      "the             -> the\n",
      "stem            -> stem\n",
      "cat             -> cat\n",
      "sh              -> sh\n",
      "ould            -> ould\n",
      "identify        -> identifi\n",
      "such            -> such\n",
      "strings         -> string\n",
      "as              -> as\n",
      "cats            -> cat\n",
      ",               -> ,\n",
      "catlike         -> catlik\n",
      ",               -> ,\n",
      "and             -> and\n",
      "catty           -> catti\n",
      ".               -> .\n",
      "A               -> A\n",
      "stem            -> stem\n",
      "ming            -> ming\n",
      "algorithm       -> algorithm\n",
      "might           -> might\n",
      "also            -> also\n",
      "reduce          -> reduc\n",
      "the             -> the\n",
      "words           -> word\n",
      "fishing         -> fish\n",
      ",               -> ,\n",
      "fished          -> fish\n",
      ",               -> ,\n",
      "an              -> an\n",
      "d               -> d\n",
      "fisher          -> fisher\n",
      "to              -> to\n",
      "the             -> the\n",
      "stem            -> stem\n",
      "fish            -> fish\n",
      ".               -> .\n",
      "The             -> the\n",
      "stem            -> stem\n",
      "need            -> need\n",
      "not             -> not\n",
      "be              -> be\n",
      "a               -> a\n",
      "word            -> word\n",
      ",               -> ,\n",
      "for             -> for\n",
      "ex              -> ex\n",
      "ample           -> ampl\n",
      "the             -> the\n",
      "Porter          -> porter\n",
      "algorithm       -> algorithm\n",
      "reduces         -> reduc\n",
      ",               -> ,\n",
      "argue           -> argu\n",
      ",               -> ,\n",
      "argued          -> argu\n",
      ",               -> ,\n",
      "argues          -> argu\n",
      ",               -> ,\n",
      "arg             -> arg\n",
      "uing            -> u\n",
      ",               -> ,\n",
      "and             -> and\n",
      "argus           -> argu\n",
      "to              -> to\n",
      "the             -> the\n",
      "stem            -> stem\n",
      "argu            -> argu\n",
      ".               -> .\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "sentence = '''A stemmer for English operating on the stem cat sh\n",
    "ould identify such strings as cats, catlike, and catty. A stem\n",
    "ming algorithm might also reduce the words fishing, fished, an\n",
    "d fisher to the stem fish. The stem need not be a word, for ex\n",
    "ample the Porter algorithm reduces, argue, argued, argues, arg\n",
    "uing, and argus to the stem argu.'''\n",
    "\n",
    "## tokenize the sentence\n",
    "list = nltk.word_tokenize(sentence)\n",
    "\n",
    "## print each word in the sentence before and after Stemming \n",
    "for word in list:\n",
    "    print(f'{word} \\t -> {porter.stem(word)}'.expandtabs(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A stemmer for english oper on the stem cat should identifi such string as cat , catlik , and catti . A stem algorithm might also reduc the word fish , fish , and fisher to the stem fish'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "sentence = \"A stemmer for English operating on the stem cat should identify such strings as cats, catlike, and catty. A stemming algorithm might also reduce the words fishing, fished, and fisher to the stem fish\"\n",
    "tokenized_words = word_tokenize(sentence)\n",
    "tokenized_sentence = []\n",
    "for word in tokenized_words:\n",
    "    tokenized_sentence.append(porter.stem(word))\n",
    "tokenized_sentence = \" \".join(tokenized_sentence)\n",
    "tokenized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "حرك\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.isri import ISRIStemmer\n",
    "st = ISRIStemmer()\n",
    "w='حركات'\n",
    "print(st.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n",
      "program\n",
      "program\n",
      "program\n",
      "cak\n",
      "ind\n",
      "mat\n",
      "===============================\n",
      "dog\n",
      "program\n",
      "program\n",
      "program\n",
      "cake\n",
      "indic\n",
      "matric\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "StemmerLancaster = LancasterStemmer() \n",
    "Stemmerporter = PorterStemmer() \n",
    "\n",
    "list=['dogs', 'programming', 'programs', 'programmed',\n",
    "      'cakes', 'indices', 'matrices']\n",
    "\n",
    "for word in list:\n",
    "    print(StemmerLancaster.stem(word))\n",
    "    \n",
    "print('===============================')\n",
    "\n",
    "for word in list:\n",
    "    print(Stemmerporter.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Lemma               \n",
      "A                   A                   \n",
      "stemmer             stemmer             \n",
      "for                 for                 \n",
      "English             English             \n",
      "operating           operating           \n",
      "on                  on                  \n",
      "the                 the                 \n",
      "stem                stem                \n",
      "cat                 cat                 \n",
      "should              should              \n",
      "identify            identify            \n",
      "such                such                \n",
      "strings             string              \n",
      "as                  a                   \n",
      "cats                cat                 \n",
      "catlike             catlike             \n",
      "and                 and                 \n",
      "catty               catty               \n",
      "A                   A                   \n",
      "stemming            stemming            \n",
      "algorithm           algorithm           \n",
      "might               might               \n",
      "also                also                \n",
      "reduce              reduce              \n",
      "the                 the                 \n",
      "words               word                \n",
      "fishing             fishing             \n",
      "fished              fished              \n",
      "and                 and                 \n",
      "fisher              fisher              \n",
      "to                  to                  \n",
      "the                 the                 \n",
      "stem                stem                \n",
      "fish                fish                \n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "sentence1 = \"He was running and eating at same time. He has bad habit of swimming after playing long hours in the Sun.\"\n",
    "\n",
    "punctuations=\"?:!.,;\"\n",
    "sentence_words = nltk.word_tokenize(sentence)\n",
    "for word in sentence_words:\n",
    "    if word in punctuations:\n",
    "        sentence_words.remove(word)\n",
    "sentence_words\n",
    "print(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\n",
    "for word in sentence_words:\n",
    "    print (\"{0:20}{1:20}\".format(word,wordnet_lemmatizer.lemmatize(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A                   A                   \n",
      "stemmer             stemmer             \n",
      "for                 for                 \n",
      "English             English             \n",
      "operating           operate             \n",
      "on                  on                  \n",
      "the                 the                 \n",
      "stem                stem                \n",
      "cat                 cat                 \n",
      "should              should              \n",
      "identify            identify            \n",
      "such                such                \n",
      "strings             string              \n",
      "as                  as                  \n",
      "cats                cat                 \n",
      "catlike             catlike             \n",
      "and                 and                 \n",
      "catty               catty               \n",
      "A                   A                   \n",
      "stemming            stem                \n",
      "algorithm           algorithm           \n",
      "might               might               \n",
      "also                also                \n",
      "reduce              reduce              \n",
      "the                 the                 \n",
      "words               word                \n",
      "fishing             fish                \n",
      "fished              fish                \n",
      "and                 and                 \n",
      "fisher              fisher              \n",
      "to                  to                  \n",
      "the                 the                 \n",
      "stem                stem                \n",
      "fish                fish                \n"
     ]
    }
   ],
   "source": [
    "for word in sentence_words:\n",
    "    print (\"{0:20}{1:20}\".format(word,wordnet_lemmatizer.lemmatize(word, pos=\"v\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed sentence\n",
      "فن ابداع\n",
      "Stemmed sentence\n",
      "stem sentenc فن ابداع \n"
     ]
    }
   ],
   "source": [
    "file=open(r'C:\\Users\\asus\\Desktop\\file.txt',encoding = 'UTF-8')\n",
    "Sentences= file.read()\n",
    "\n",
    "def stemSentence(sentence):\n",
    "    token_words=word_tokenize(sentence)\n",
    "    token_words\n",
    "    stem_sentence=[]\n",
    "    for word in token_words: \n",
    "        stem_sentence.append(porter.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)\n",
    "    \n",
    "print(Sentences)\n",
    "print(\"Stemmed sentence\")\n",
    "x = stemSentence(Sentences)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
